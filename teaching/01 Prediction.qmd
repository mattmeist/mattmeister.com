---
title: "01 - Prediction"
include-in-header:
  - text: |
      <style>
      .code-fold-block {
          margin-bottom: 1em;
          border: 1px solid #ddd;
          border-radius: 5px;
          overflow: hidden;
      }
      .code-fold-header {
          background-color: #f7f7f7;
          padding: 0.5em;
          cursor: pointer;
          font-weight: bold;
          border-bottom: 1px solid #ddd;
      }
      .code-fold-content {
          display: none;
          padding: 0.5em;
          background-color: #fdfdfd;
      }
      </style>
  - text: |
      <script>
      document.addEventListener('DOMContentLoaded', () => {
          document.querySelectorAll('.code-fold-block').forEach(block => {
              const header = block.querySelector('.code-fold-header');
              const content = block.querySelector('.code-fold-content');
              header.addEventListener('click', () => {
                  const isHidden = content.style.display === 'none';
                  content.style.display = isHidden ? 'block' : 'none';
              });
          });
      });
      </script>
format: 
  html:
    self-contained: true
    theme: flatly
    fontsize: 12pt
    code-fold: false  # Disable default code folding
code-block-bg: true
#code-block-border-left: "#31BAE9"
editor: source
execute: 
  error: true
  echo: true
  include: true
  warning: false
---

## Pre-Class Code Assignment Instructions


In this semester, I am going to ask you to do a fair bit of work before coming to class. This will make our class time shorter, more manageable, and *hopefully* less boring.

I am also going to use this as an opportunity for you to directly earn grade points for your effort/labor, rather than "getting things right" on an exam.

Therefore, I will ask you to work through the posted slides on Canvas before class. Throughout the document, I will post **Pre-Class Questions** for you to work through in `R`. These will look like this:

<h4 style="color: darkgreen;">Pre-Class Q1</h4>

<span style="color: darkgreen;">In `R`, please write code that will read in the `.csv` from Canvas called `sf_listings_2312.csv`. Assign this the name `bnb`.</span>

You will then write your answer in a .r script:

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
# Q1
bnb <- read.csv("sf_listings_2312.csv")
```

  </div>
</div> 


### Important: 

To earn full points, you need to organize your code correctly. Specifically, you need to:

- Answer questions in order.
  - If you answer them out of order, just re-arrange the code after.
- Preface each answer with a comment (`# Q1`/`# Q2`/`# Q3`) that indicates exactly which question you are answering.
  - Please just write the letter Q and the number in this comment.
- Make sure your code runs on its own, on anyone's computer.
  - To do this, I would always include `rm(list = ls())` at the top of every .r script. This will clean everything from the environment, allowing you to see if this runs on my computer.
  

### Handing this in:


- You must submit this to Canvas **before 9:00am on the day of class**. Even if class starts at 10:00am that day, these are always due at 9:00.
- You must submit this code as a `.txt` file. This is because Canvas cannot present `.R` files to me in SpeedGrader. To save as `.txt`:
  - Click File -> New File -> Text File
  - Copy and paste your completed code to that new text file.
  - Save the file as `firstname_lastname_module.txt`
    - For example, my file for Module 01 would be `matt_meister_01.txt`
    - My file for module 05 would be `matt_meister_05.txt`
    
    
### Grading:


- I will grade these for completion. 
- You will receive 1 point for every question you give an honest attempt to answer
- Your grade will be the number of questions you answer, divided by the total number of questions.
  - **This is why it is important that you number each answer with** `# Q1`.
  - Any questions that are not numbered this way will be graded incomplete, because I can't find them.
- You will receive a 25% penalty for submitting these late.
- I will post my solutions after class.

## Prediction

Load in these packages. If you do not have them, you will need to install them.

- e.g., `install.packages("tidytext")`

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
library(tidytext)
library(stringr)
library(dplyr)
library(ggplot2)
```

  </div>
</div> 

And read in these data:

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
bnb <- read.csv("sf_listings_2312.csv")
```

  </div>
</div> 


### Why are we doing this?

The goal of data analysis/science is to make predictions about the future.

We do not just analyze data to find some neat facts about Airbnb properties (for example). We analyze data to understand how the world works. Because that will give us our **best guess** about how the world **will work** in the future.

And we have some control over the future! The things we discover about the past are helpful **only** because they can inform the choices we make for the future.
 
#### For example:

One of the common praises of Airbnbs is that they are often larger than hotels, allowing friends to stay together. If it is true (that staying together is a benefit of Airbnbs), we should find that Airbnbs that accommodate more people get higher ratings than Airbnbs who accommodate fewer people.


<h4 style="color: darkgreen;">Pre-Class Q2</h4>

In R, test with linear regression whether listings that accommodate more people receive higher ratings.

**Note: The variable for average rating is called** `review_scores_rating`.

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
summary(lm(data = bnb, review_scores_rating ~ accommodates))
```

  </div>
</div> 


<h4 style="color: darkgreen;">Pre-Class Q3</h4>

Do listings who accommodate more people receive higher ratings? Answer this in a comment.

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
# Yes. The coefficient is > 0, and the p-value is very low. This suggests that places who accommodate more people receive significantly higher ratings.
```

  </div>
</div> 



This result tells us something about the future because the *p-value* indicates that the relationship between `review_scores_rating` and `accommodates` is stronger than we would expect from chance alone. Therefore, it is not due to randomness that larger places received higher ratings. 

One condition that we have to satisfy in order to use past data to predict the future is that the results we observe must **not** be due to chance. Because chance is random. This is easy to test by looking at *p-values*. We have just done this for a single variable (`accommodates`), but we can also do it for multiple variables. 


## Model Comparison

The world is a complicated place. While we often care about individual variables, it is more common that we want to create (semi-) complex models, which use multiple variables to predict an outcome. To know whether adding this complexity is worth it, or which of a series of models will best predict the future, we have to compare those models. 

We will cover two forms of model comparison. First, using `anova()`. Second, splitting our data into training and testing sets.


#### Anova

Anova is an acronym for **analysis of variance**. It takes two models, and analyzes the degree to which the variance reduced by the more complex one is larger than chance.

**Advantages:**

- Relatively simple to code and run
- Requires less data than training/testing sets
- Provides a *p-value*, which is familiar

**Disadvantages**

- Not very common anymore (because we have more data than we used to)
- Cannot compare models of equal complexity
  - e.g., Cannot compare `rating ~ price` to `rating ~ accommodates`

That second disadvantage is pretty substantial. As a result, you won't see this as much. 


If I wanted to see whether a model with `accommodates` and `price` predicted `review_scores_rating` better than a model with `accommodates` alone, I could do the following.

First, let's look at the variables we have:

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">

```{r}
hist(bnb$review_scores_rating)
hist(bnb$accommodates)
hist(bnb$price)
```

  </div>
</div> 

Whoa! `price` threw an error. This is because it is not numeric. It has that annoying \$ before it, and also has a , when prices are in the thousands. We'll need to remove those with the following code:

<h4 style="color: darkgreen;">Pre-Class Q4</h4>

<span style="color: darkgreen;">Just copy this into R.</span>

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
# First, remove the dollar sign
bnb$price <- str_remove(bnb$price, "\\$")
# You need the "\\" because $ is a special character with regular expressions, but we just want the symbol gone.

# Second, remove the comma
bnb$price <- str_remove(bnb$price, ",")

# Third, make this a number
bnb$price <- as.numeric(bnb$price)
```

  </div>
</div> 


<h4 style="color: darkgreen;">Pre-Class Q5</h4>

See whether a model with `accommodates` and `price` predicted `review_scores_rating` better than a model with `accommodates` alone.

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
model_simple <- lm(data = bnb, review_scores_rating ~ accommodates)
model_complex <- lm(data = bnb, review_scores_rating ~ accommodates + price)
anova(model_simple, model_complex)
```

  </div>
</div> 


That p-value being extremely small tells me that the variance reduced by the more complex model was well worth the added complexity. This should make us confident that using the complex model will lead to better predictions in the future than using the simpler model.


### Train/Test Splits

Another way we can do this model comparison is by splitting our data into two sets (training and testing), and seeing how well each model that we **fit** to the training set **predicts** the testing set.

**Advantages:**

- Super common (especially in machine learning)
- Very flexible--can use different variables, models, etc
- Rather than a p-value, we can directly compare the error between models
  - This is because the p-value is approximating what we are actually doing here

**Disadvantages**

- Needs more data to be reliable
- More complex to code


#### First: split our data into a training and a testing set

- Usually, the training set is 70%-80% of the data.
- We do this by randomly sampling our data with `sample()`.
  - We should randomly sample the `id`, as this is unique to each row.
- Because there is randomness, we will use `set.seed()` to get consistent results.

<h4 style="color: darkgreen;">Pre-Class Q6</h4>

Create splits of `bnb` into training and testing data.

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
set.seed(28)
samp_size <- round(.7 * nrow(bnb)) # I am rounding this to get a whole number
train <- sample(bnb$id, size = samp_size, replace = FALSE)

bnb_train <- bnb[bnb$id %in% train,] # Index bnb where the id is inside train
bnb_test <- bnb[!(bnb$id %in% train),] # Index bnb where the id is NOT inside train
```

  </div>
</div> 

#### Second: **train** each model on the training set

<h4 style="color: darkgreen;">Pre-Class Q7</h4>

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
model_simple_train <- lm(data = bnb_train, review_scores_rating ~ accommodates)
model_complex_train <- lm(data = bnb_train, review_scores_rating ~ accommodates + price)
```

  </div>
</div> 


**Note**: You need to use `bnb_train` as the data, not `bnb`. Also, if you look at `model_simple` and `model_simple_train`, you will see the coefficients are slightly different. Think of why this is.


#### Third: **test** each model on the testing set. 

<h4 style="color: darkgreen;">Pre-Class Q8</h4>

Do this by:

a) Making predictions about `review_scores_rating` from each model.
b) Calculating the **squared error** for each model.
c) Comparing those numbers.

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
#a) predictions
bnb_test$prediction_simple <- predict(object = model_simple_train,
                             newdata = bnb_test, 
                             type = "response")

bnb_test$prediction_complex <- predict(object = model_complex_train,
                             newdata = bnb_test, 
                             type = "response")

#b) calculate error
bnb_test$error_simple <- (bnb_test$prediction_simple - bnb_test$review_scores_rating)^2

bnb_test$error_complex <- (bnb_test$prediction_complex - bnb_test$review_scores_rating)^2

#c) compare error
mean(bnb_test$error_simple, na.rm = T)
mean(bnb_test$error_complex, na.rm = T)
```

  </div>
</div> 

- `predict()` spits out a prediction for each row in the new data when we specify `type = "response"`.
  - This is why we can just attach it as a column.


In this case, because we are actually making predictions, we do not need p-values. We can just look at the reduction in error itself.

One thing you will notice is that we *barely* reduced any error from the average prediction. If that seems odd, you can try different things:

- Cross-validation [(described here)](https://www.geeksforgeeks.org/cross-validation-in-r-programming/) 
  - This repeats the process we just did (splitting, training, testing) multiple times on the same set of data, potentially reducing the impact of randomness in our sampling
- Variable selection
  - `price` is not normally distributed at all. So we may be getting some weirdness in the results as a result. You could see how results change if you transform `price` somehow.
  
  
## Actually Making Predictions

The simple model (from the `anova()` example) predicts `review_scores_rating` as the following function:

- `review_scores_rating`~i~ = 4.68 + 0.027 $\times$ accommodates~i~
  - In this function, $i$ denotes any individual listing.
  
The complex model predicts `review_scores_rating` as the following function:

- `review_scores_rating`~i~ = 4.68 + 0.027 $\times$ accommodates~i~ + -0.000016 $\times$ price~i~ 


### Why does this matter?

With the simple model, we predict that the cheapest and the most expensive 4-person Airbnb would have the exact same ratings.

<h4 style="color: darkgreen;">Pre-Class Q9</h4>

See these predictions with `predict()`. To use `predict()`, we need to create a new `data.frame` that has the exact same variables as the variables in our models.

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
# Minimum price for a four-person bnb
min_fourperson <- min(bnb[bnb$accommodates == 4, ]$price)
# Maximum price for a four-person bnb
max_fourperson <- max(bnb[bnb$accommodates == 4, ]$price)

new_data <- data.frame(
  accommodates = c(4, 4),
  price = c(min_fourperson, max_fourperson)
)

predict(object = model_simple, #Predict takes an "object" (a model)
        newdata = new_data, # and it takes "newdata"
        type = 'response') 
```

  </div>
</div> 

<h4 style="color: darkgreen;">Pre-Class Q10</h4>

With the complex model, we **do not** predict that the cheapest and the most expensive 4-person Airbnb would have the exact same ratings. On your own, I want you to make those predictions for the complex model.


#### Making variables behave

Now, if you look at the distribution of `price`, you will see that it is a bit... crazy. For example, the maximum price of a four-person Airbnb is \$50,000 **per night**!

You will probably get better predictions if you enforce some normality on `price`. On your own, I would like you to:

<h4 style="color: darkgreen;">Pre-Class Q11</h4>

- Create a new variable called `bnb$log_price`, which will be the natural log of `bnb$price` (Google this).
- Create a new model called `model_complex_log`, using `log_price` in place of `price`.
- Use `anova() to compare the simple model to this new complex model. Is it still better?

You will probably get better predictions if you enforce some normality on `price`. 

## Final Questions

These questions are for added points/difficulty. They count towards the total score. 

<h4 style="color: darkgreen;">Pre-Class Q12</h4>

You are not going to be able to test the original `model_complex` against `model_complex_log` using `anova()`. But, you can test these two using the training/testing example from earlier. Try to do that here.

<h4 style="color: darkgreen;">Pre-Class Q13</h4>

I would like you to challenge yourself here, by attempting to test a totally new set of models. Predict `review_scores_rating` with new variables, using both `anova()` and training/testing splits.

## In Class

In class, we are going to try out making predictions of `review_scores_rating` using whatever variables we want. You will then hand in your best models as your homework.

If you just use the variables that are already in the data set, you will struggle. Instead, I suggest creating new ones, cleaning the ones you have, etc.

For example, you might want to distinguish places that accommodate more than four people categorically:

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
bnb$accommodates_5plus <- ifelse(bnb$accommodates > 4, 1, 0)
```

  </div>
</div> 

And then see if this predicts ratings:

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
model_5plus <- lm(data = bnb, review_scores_rating ~ accommodates_5plus)
summary(model_5plus)
```

  </div>
</div> 

You might also want to pull out some specific amenity. **Any time you are handling text, make it lower case!**

<div class="code-fold-block">
  <div class="code-fold-header">Click to show code and output</div>
  <div class="code-fold-content">
  
```{r}
bnb$amenities <- tolower(bnb$amenities)
bnb$kitchen <- ifelse(str_detect(bnb$amenities, 'kitchen'), 1, 0)
```

  </div>
</div> 

